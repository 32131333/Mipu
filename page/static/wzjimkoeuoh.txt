30.12.2025
Original Sound в постах Mipu Sparks

Основные типы деления:
1. Исходящие -> Типа являются самими распространителями
2. Используемые -> В случае с видеоконтентом они либо типа перезаписываются, либо при желании оригинальный звук воспроизводится фоном, а на картинках просто фоном воспроизводятся
ОНО МАКСИМАЛЬНА ТИПА УСЛОВНАИ ПОТОМУШТО Я НЕ ГАРАНТИРУЮ ЧТО ЕТО БУДИТ ТАК

Почему это сложно:
1. Философия Sparks. Оно включает в себя по своей природе просто улучшение вертикального формата с идеей, что оно не просто вертикальное, но и универсальное. Один пост Sparks может включать в себя до несколько картинок и видео одновременно, что нетипично вообще для TikTok, в YT Shorts так вообще картинки по сути прикреплять нельзя(оно и понятно, что YouTube)
2. Архитерактура. По сути я переписал полностью весь API на более сложную систему чтобы устранить потенциальные проблемы, связанные с маштабированием, но по сути исрпавление проблемы не гарантируется. По сути, мне приходится использовать до нелсколько этих типа звуков, чтобы сделать видео и картинки совместимыми. Однако, в инженерии API я пока что не встречался с подобной, по сути, проблематикой
3. Концептуально-инженерная слепота. Ты никогда не знаешь, что в итоге выйдет. Чаще всего, что планировалось, и вовсе не происходит. Большую часть кода я писал вслепую и чаще не опираясь на то, как оно вообще будет выглядеть. Например, раньше, я предлагал, что mipuadv_posts(Sparks) будет развлетвлением текстовых постов, но в итоге я превратил его в отдельную структуру в таблице, вообще не думая в конечном итоге. По сути, если ты создаешь хотябы развлетвление от чего-то, а не просто внаглую копируешь, то по сути ты выдумываешь что-то инновационное, прям также, как Стив Джобс тогда представлял iPhone(по сути, его великолепные айфоны - это отвлетвление от классического телефона). Главная проблема очевидна - у тебя отсутствует полный подход к реализации этого, но в этом тебя викто не винит
4. Отсутствие какой-либо команды, поддержки. Я буквально пишу это все в одиночку, без поддержки, без денег, без ничего. У меня нету аудитории, нету тех типов, на которых я мог бы отложить задачи, исключая чат-ассистентов. Нету тех, кто бы вообще бы поддержал бы Mipu. По сути, истинные творения даже и не требуют денег, всмысле огромного вложения, которые обратят кого угодно на высь, но является ли Mipu истинным творением - я не знаю. Например, я точно не считаю за мессенджер MAX чем-то истинным, так как по сути это фулл-копирка Telegram за бешеные деньги
5. Это не совсем то же самое, что написать всю систему Sparks. По сути, Sparks - это буквально просто YouTube и TikTok в одном. Но аудио - это не видео, ни картинки
6. Авторские права. Определенно, у каждого аудио или даже видео есть авторское право. Но по сути я вабще не вникаю, что мне может быть за это
7. Некоторые зависимости. Я определил, что у TikTok есть соотнесение названия аудио с треком, которое оно хотябы на 80% совпадает, просто меняя название и обложку, и давая композитору некое право на распространение внутри этого контента, если конечно он сам зарегистрирован в TikTok, но по сути, это чей-то дорогущий API
8. До несколько видео. Это типо да, по сути, со всех них нужно вырезать аудио. И надо как-та типа так действовать, чтобы вырезать типа аудио из пад них типа да, типа да


Основная концепция:
1. Что будет представлять из себя вообще Original Sound -> вшиваемая структура в Sparks
- По типу, в Sparks оно будет примерно так расписано: {..., content: [], originalsounds: [{id: 1}, {id: 2}]} или что-то подобное
2. По сути аудиоконтент пока что не будет существовать в отдельном виде, но если неожиданно юзеру захочется использовать аудио из видео, то с радостью, система на ходу вырежет аудио из видео.
3. Перезаписывать или фоново проигрывать? Такой вопрос стоит у видеоконтента. По сути, перезаписывать это отличная мысль, особенно, если юзер захочет скачать видео, а с другой точки зрения, оно могло бы синхронизироваться с аудиоконтентом для картинок, но это вопрос абсолютна типа вапрос







//
originalsounds: [[1,2]] <- sparksid, videoindex
Или ["1_2", "1"] <- sparksid_videoindex , или sparksid(тогда videoindex будет 0)

В content будет типо так:
- ["1", "2_3", "12"]
- [{"id": "image"}, {"id": "video", "soundindex": 1}, {"id": "image": "soundindex": 2}, {"id": "video"}]
- Первый контент - картинка. Здесь данных нету, поэтому мы либо используем нулевой индекс(если он присутствует), либо вообще не используем какую-либо информацию.
- Второй контент - видео. Здесь уже использовано оригинальное аудио, поэтому, мы просто используем выданные данные в originalsounds ("2_3"). Это значит, мы вырезаем звук типа из четвертого видео в посту со вторым айди
- Третий контент - картинка. Ну тут понятное дело, воспроизводим ауди фоном
- Четвертый контент - видео без выбранного звука. Значит, оно действует независимо, поэтому пусть ссылается на самого себя ("id_3") 

Фронтенд обращаца к медиасерверу типа так: '/posts/1/sound2.ogg'
Но вот вопрос:
Обложка типа. Его чтоли вырезать из юзерской аватарки по дефалту? В TikTok обычно использоуется типа аватарка автора, в шортс превью видева типа

Ладно попробую с тем, что я выдал ["1_2", "1"] типа так
Они будут генерироваться только в случае, если ток при публикации

Но пагадите
Одного типа саунда недочтаточна. Знач мне надо что-то в духе впихать данные поста внутри поста. Но мне надо однозначно пихать по несколько постов в массив, а таких практик в API у меня никогда не было. Я не хочу возвращаться к проблеме N+1, когда сервер будет кидать запросы на то же самое типа. Я могу совершать какбы поиск по айди со стороны клиента, но вопрос больше в том, как это оптимизировать
Плюсом это JSON-массив


Но я выберу подход MVP. Пока что выберу какой-нибудь общий звук



ИЛИ
- [{"id": "image"}, {"id": "video", "ext_audio": "1_2"}, {"id": "image": "ext_audio": "2"}, {"id": "video"}]